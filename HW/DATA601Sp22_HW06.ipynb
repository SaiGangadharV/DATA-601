{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simsekergun/DATA601/blob/main/HW/DATA601Sp22_HW06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25834503-f8f5-4973-8f1d-d94c2e10aeeb",
      "metadata": {
        "id": "25834503-f8f5-4973-8f1d-d94c2e10aeeb"
      },
      "source": [
        "# DATA 601 - HW06 (Spring 22)\n",
        "Due date: May 12, 2022, 23:59 pm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USUAL SUSPECTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import bar\n",
        "import seaborn as sns\n",
        "# sklearn stuff\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "VfAr9hOd6eMX"
      },
      "id": "VfAr9hOd6eMX",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cc6ce2f4-c0b7-4990-91cf-f92018392b95",
      "metadata": {
        "id": "cc6ce2f4-c0b7-4990-91cf-f92018392b95"
      },
      "source": [
        "### Q1. (10 points)\n",
        "Training and validation dataset: https://raw.githubusercontent.com/simsekergun/DATA601/main/Datasets/HouseTraining.csv\n",
        "\n",
        "* The last column of the HouseTraining.csv file lists price of 400 houses.\n",
        "* There are 11 features\n",
        "  * School rating (integer between 1 and 10)\n",
        "  * House Area (sq ft)\n",
        "  * Lot Area (sq ft)\n",
        "  * Number of rooms\n",
        "  * Number of bathrooms\n",
        "  * Garage Yes:1, No: 0\n",
        "  * Pool Yes:1, No: 0\n",
        "  * Age of the House (years)\n",
        "  * Walkability rating (something between 1 and 10)\n",
        "  * Crime rate (something between 1 and 10)\n",
        "  * Zipcode (Note that this is a fake data) \n",
        "  * House price ($)\n",
        "\n",
        "Here are questions <br>\n",
        "<b>1.1</b> Calculate the average crime rate for each zip code determine the zipcode with highest average crime rate? <br>\n",
        "<b>1.2</b> Calculate the average house price for each zip code determine the zipcode with lowest average house price? Do you see a pattern? <br>\n",
        "<b>1.3 </b> What feature has the strongest correlation with the \"School_Rating\" <br>\n",
        "<b>1.4</b> Split your dataset into two (training 80\\%, validation (testing) \\%20, random_state=1). Build a multiple linear regression model to estimate the house price from all the other features we have and calculate the maximum relative error using $100*\\mathrm{max}|(y_i-\\hat{y}_i)/y_i|$ and $R^2$, where $y_i$ is the true value for the $i^{th}$ case in your testing data set and $\\hat{y}_i$ is the prediction. <br>\n",
        "<b>1.5</b> Download the new test dataset (https://raw.githubusercontent.com/simsekergun/DATA601/main/Datasets/HouseTest.csv), guess the prices of these 10 houses featured in this dataset and print your predictions. Note that this dataset doesn't include \"House_Price\" column which was given in the training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d41f9847-94e1-4cd8-8d0c-09b353bcf1e8",
      "metadata": {
        "id": "d41f9847-94e1-4cd8-8d0c-09b353bcf1e8"
      },
      "source": [
        "## Q2. (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fed6b1fa-9698-4a90-9431-8c0be84a8691",
      "metadata": {
        "id": "fed6b1fa-9698-4a90-9431-8c0be84a8691"
      },
      "source": [
        "The Default data set of the ISLR2 package contains data about ten thousand customers. We know the balance of their bank account, their annual income and whether they are a student. You can download the dataset here: https://github.com/simsekergun/DATA601/blob/main/Datasets/Default.xlsx?raw=true'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0cacba4-a30a-435a-8ce1-2417f9a1ea59",
      "metadata": {
        "id": "e0cacba4-a30a-435a-8ce1-2417f9a1ea59"
      },
      "source": [
        "Let's replace yes' and no's with 1's and 0's using the factorize() function. Note that factorize() returns two objects: a label array and an array with the unique values. We are only interested in the first object, i.e. <br>\n",
        "<code>df = pd.read_excel('https://github.com/simsekergun/DATA601/blob/main/Datasets/Default.xlsx?raw=true',index_col=[0]) </code> <br>\n",
        "<code>df['default'] = df.default.factorize()[0]</code>  <br>\n",
        "<code>df['student'] = df.student.factorize()[0]</code> <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "232a3cc0-5917-4260-85f2-ef17717c62b0",
      "metadata": {
        "id": "232a3cc0-5917-4260-85f2-ef17717c62b0"
      },
      "source": [
        "Here the steps/questions you need to follow <br>\n",
        "<b>2.1</b> Plot the histograms of the features in this dataset. What kinds of distributions do you see? <br>\n",
        "<b>2.2</b> Boxplot 'default vs balance' and 'default vs income'. Which one has outliers? <br> \n",
        "<b>2.3</b> Split your dataset into two (training 80\\%, validation (testing) \\%20, random_state=1). Build a simple logistic regression model to predict default from balance feature only. Create the confusion matric and calculate accuracy, sensitivity, and specificity. <br> \n",
        "<b>2.4</b> Repeat 2.3 but this time use 'balance', 'income', and 'student' features to predict the default with a multiple logistic regression model. Create the confusion matric and calculate accuracy, sensitivity, and specificity.  <br>\n",
        "<b>2.5</b> What does having a high sensitivity and a low specificity mean?<br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bBRobdFd6uuR"
      },
      "id": "bBRobdFd6uuR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "DATA601Sp22_HW06.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}